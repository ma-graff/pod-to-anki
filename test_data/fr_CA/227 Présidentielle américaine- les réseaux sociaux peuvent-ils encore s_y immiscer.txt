La campagne électorale fédérale

vient de se terminer et jusqu? À présent, aucune trace de

ingérences étrangères n'a été décelée dans notre processus

électoral. On a donc été épargné, mais chez nos voisins

du Sud, 12 mois les sépare du prochain scrutin et, déjà, des

manoeuvres d'ingérence étrangère ont été détecter et

neutraliser sur un réseau social majeur.

Notre question à un an de la présidentielle américaine,

où en est la lutte à l'ingérence étrangère sur

les réseaux sociaux? Notre invité, Jeff yates, je suis

journaliste au décrypteurs. Radio-Canada, moi, je

m'appelle Alexis de lancer et c'est parti pour. Ça

s'explique de balader qui s'intéresse à l'actualité,

une question à la fois.

Bravo.

Mark Zuckerberg, PDG et fondateur du géant Facebook on

l'entendait ici dire sur le réseau NBC Jeff c'était le 22

octobre dernier, que depuis les élections de 2016, son empire a

changé. Récemment, on a vu en tout cas peut être les fruits de

ces changements là. 50 comptes Instagram, qui est la propriété

de Facebook qui aurait été gérée depuis la Russie, ont été

fermées. De quoi il s'agit exactement donc c'était des faux

comptes qui tentaient de faire essentiellement exactement la

même chose qui a été fait dans l'élection de 2016, donc une

tentative. De s'immiscer dans le processus électoral américain.

Donc juste pour revenir en arrière un peu. Ce qui a été

fait en 2016, c'est que bon, il y a toute une panoplie de faux

comptes, de fausses pages Facebook qui avait été créé

Instagram aussi bien sûr dans le but de mobiliser des communautés

particulières. Donc on avait créé des faux comptes, par

exemple pour le mouvement Black lives ****** on avait créé des

faux comptes pour le mouvement LGBT aux États-Unis, mais aussi

de l'autre côté. On avait créé des faux comptes pour le droit

du port des armes.

Des faux comptes pour arrêter l'immigration massive bref, on

essaie de toucher tous les sujets sensibles dans la

politique américaine, donc le but c'était en premier lieu de

créer une des communautés autour de ces enjeux là. L'ensemble des

message qui qui saura plaire aux gens qui qui s'identifient à ces

groupes là et. Et puis de plus en plus qu'on s'approchait de

l'élection, de lancer des messages qui divisent les gens,

voire même qui découragent le vote chez certains donc par

exemple on a vu dans les les fausses pages de communauté

noire on disait bon, c'est pas dans l'intérêt des noirs d'aller

voter. Donc, et en sachant très bien que les communautés noires

aux États-Unis votent quand même beaucoup démocrate. Donc bon,

l'intention était de décourager le vote plutôt que de convaincre

les les communautés noires de voter pour Donald Trump. On a

plutôt décidé de décourager leur vote, donc ça faisait depuis la

Russie en 2016. Mais là, si on se ramène à l'opération qui les

50 comptes fermer au cours de la dernière semaine, c'est la même

chose exactement la même chose en fait. D'ailleurs, le

l'entreprise d'analyse graphique

akita. Analyser, c'est faux contre là pour Facebook a nommé

la campagne copy paste. Donc parce que on on copier

littéralement de copier coller exactement et c'est contre. Là

ont été détectés en début de parcours, donc c'est contre là

pour la plupart n'avaient pas beaucoup d'abonnés dont la

moitié avait moins que 5000

abonnés. Euh, et on n'était pas à l'étape où on cherche à

décourager le vote. Où, où mettre de l'avant, de la

désinformation ou quelque chose comme ça? C'est vraiment. Ils

étaient dans le processus de bâtir les communautés, donc on a

envoyé des message encore une fois pour tenter d'aller

chercher des abonnés et de mobiliser les groupes qu'on

visait. Essai Facebook la compagnie elle-même, qui a

révélé tout à fait qui a réveillé tout ça, c'est ouais,

tout à leur avantage aussi là Ben c'est ça, c'est que ça

envoyer un message quand même. Donc avec l'élection de 2016,

toutes les histoires d'ingérence étrangère, il y avait, il y

avait beaucoup de gens qui suspectait qui avait bon des

comme on dit en anglais, Dirty

tricks avec l'élection. Alors ça en 2016, sur les réseaux

sociaux, mais c'est vraiment après l'élection que tout sa

sortie que finalement il y avait eu des des réseaux de faux

comptes et de fausses pages. Qui avait cherché à s'immiscer dans

la campagne et sa sortie par après? Ouais, là ce qui est

intéressant dans ce cas-là, c'est que ça sort avant un an,

plus d'un an avant l'élection déjà on dit bah Regardez, on a

retiré ses contre, là c'est à l'avantage de Facebook donc donc

c'est un bon coup de marketing de dire mais Regardez on est à

l'affût, on ne laissera pas ce qui s'est passé en 2016. Se

reproduire en 2020. On surveille ce qui se passe et donc c'est un

changement. On entendait Mark Zuckerberg plutôt dire que

Facebook a changé. Bon force est de constater que c'est c'est

vrai, donc il y a eu quand même des changements majeurs. On n'a

pas vu de d'efforts du genre avant avant l'élection de 2016.

Reste que c'était quand même un réseau nous somme toute mineure.

On parle d'une cinquantaine de compte Instagram, là c'est

pas là, c'est c'est pas le gros gros, gros gros réseau,

mais déjà c'est quand même intéressant de voir que on

agit en amont plutôt que après l'élection.

Fake news.

Ah, il faut.

Une déclaration, je présume qu'il va hanter longtemps Mark

Zuckerberg en 2016, qui affirmait donc c'est

complètement fou cette idée salon. Laquelle des fausses

nouvelles pour aide quelconque façon à influencer le processus

électoral? Ouais, mais là il, il l'a bien constaté que c'est ça

qui s'est produit, n'a pas eu le choix d'agir. On le disait

tantôt. Qu'est-ce qui a été fait

depuis? Tout plein de choses d'une part, bon, la pression

a été mise sur les géants de réseaux sociaux pour faire

quelque chose.

Devoir Mark Zuckerberg va être contraint à témoigner

devant le Congrès américain.

Xbox chairman and co ZA Cooper. Déjà là, hum.

Le jour et la nuit là, avant de avant 2/5/2016 concrètement bon,

Facebook mise sur pied, beaucoup d'initiatives pour dire, il y a

la partenariat de fact-checking avec l'international Factory

Network, dont les décrypteurs font partie. Ouais, donc c'est

un consortium indépendants complètement indépendante,

Facebook qui certifient des équipes médiatique qui font de

la vérification des faits, du fact checking et Facebook offre

des partenariats aux aux médias qui font partie de ça pour être

des partenaires de fact-checking sur la plateforme. Donc au

Canada, il y a seulement la FP.

Pour le, pour le moment, ouais, qui vérifie ça? Et donc quand la

p tranche que une une information est fausse, donc

écrivez un article qui disent que c'est faux. Facebook qui est

supposé non seulement de montrer un avertissement à toute

personne qui tentent de partager cette fausse information là,

mais aussi de baisser la portée. Quatre-vingts pour 100 moins

personne le voit dans le fond, en gros ça c'est dur à vérifier

et on n'a pas accès aux données internes de Facebook donc on on

s'en remet un peu à leur bonne volonté de ce côté-là mais c'est

ce qu'ils affirment aussi toutes sortes de de mesures pour tenter

de amputer les revenus des pages qui font du contenu qui

et qui n'est pas très bon ou même mensonge et donc donc ne

pas permettre à des pages qui proposent souvent des fausses

informations, de faire la promotion de leurs articles avec

des publicités par exemple. Parce qu'il finisse, c'est fini

donc sauf pour les candidats, ça, c'est ça, c'est une autre

histoire. Donc oui, Facebook a décidé par contre que

l'exception et que les politiciens et les groupes qui

ont droit de la publicité pendant les élections peuvent

mentir dans les publicités. Donc on affirme que Ben c'est dans

l'intérêt public. Que les gens puissent voir que leurs

politiciens mentent et que ce n'est pas là, ce n'est pas là le

rôle de Facebook de décider ce qui est vrai ou non pendant une

élection. Mais il y a quand même un certain mérite à cette on

veut pas que Facebook décide de ce qui est vrai ou non pendant

une élection, mais on veut pas que Facebook décide ce qui est

vrai ou non, point. Mais il y a peut-être une discussion plus

large à avoir de ce côté-là. Ouais, c'est ça monsieur

Zuckerberg d'ailleurs, qui évoque aussi la liberté

d'expression alors que le le rival, si on veut Twitter, lui

ouais, c'est fini, c'est fini les publicités pour Twitter,

dont les listes électorales.

Pour les candidats ouais, il y a aussi le référencement qui fait

partie des des changements qui ont été apportés aussi. Ouais,

donc toute page qui propagent des fausses informations à

répétition, la, euh, et supposé de perdre mon Premièrement son

son petit crochet qui certifient comme une page une page vérifiée

mais que son référencement donc sa portée dans Facebook diminuer

on le voit que il y a des mauvais acteurs qui se

plaignent, hum, que leur portée. Bon il publie l'article sur

Facebook et une attaque personne et il y a toutes sortes de

problèmes, il y a des médias de

fact-checking par exemple. Qui sont des références et parce que

Facebook jusqu à leur publication, contient des

fausses informations. Alors qu'il tente tout simplement de

corriger la faute d'informations. Donc ça, ça

cause tout plein de maux de tête aussi. Il y a un revers à la

médaille et l'intelligence artificielle plusieurs niveaux à

la grande solutions. Est-ce qu'il y a eu des progrès dans ce

sens là? Mais Facebook affirme travailler sur des des méthodes

utilisant la l'apprentissage machine pour détecter toutes

sortes de soi, des défauts d'information ou même

l'utilisation inauthentique de

sa plateforme. Euh, ça encore, on s'en remet à leur bonne

volonté. On sait pas comment tout ça fonctionne, mais

Facebook affirme par exemple avoir retiré des centaines de

millions de faux comptes sur sa plateforme avant même que c'est.

C'est faux. Contre le souhaites créer donc dans pendant que la

personne créer un faux compte. Déjà Facebook le détecter avant

même que ça soit publié. Ce compte là ne permettent pas à la

personne de de de créer son compte, donc ils peuvent

analyser les comportements des typique, des gens qui créent des

faux comptes par exemple. Donc il y a quand même des avenue

intéressante de ce côté-là.

Ils veulent aller le plus loin, ils veulent mettre au point des

logiciels du genre qui peuvent par exemple détecter les les

discours. Venue des choses comme ça, vous, des des appels à des

incitations à la violence ou des choses comme ça, et c'est quand

même un enjeu important parce qu'il y a beaucoup des discours

qui s'en vont dans des des avenue privée, voire même

secrète sur Facebook, dans les groupes fermé et secret. Et là

il y a personne là-dedans. Pour surveiller, donc à Facebook, dit

que ils ont des, ils ont mis au point des logiciels qui peuvent

détecter ces choses-là. Mais il y a quand même certaines

questions à se poser. Ouais, sur l'efficacité de ces choses-là.

Faut pas oublier que dans tout ça, le cadre de référence Jeff,

sa demeure 2016. Alors est-ce qu'il y a un risque qu'on qu'on

s'attarde aux méthodes 2016 et aux méthodes 2016 seulement à

ce pattern là et qu'on ne voit pas passer d'autres méthodes

qui qui peuvent être plus efficacement? Mais la question

se pose donc, on a annoncé en grande pompe la semaine

dernière avoir détecté 50 faux contre là, et je sais pas si

c'est une coïncidence, mais c'est contre. Là faisait

exactement la même chose qu'en 2016.

Donc, est-ce qu'on surveille seulement ce qui était en 2016?

Il y a des toutes sortes de nouvelles méthodes qui vont être

mises au point pour la santé de jouer dans les élections. Ça se

peut écouter son temps de faire des campagnes de désinformations

puisqu'on était assez motivé, qu'on a l'argent ou les

ressources pour le faire, la limite, c'est vraiment le

l'imagination des gens qui veulent mal faire. Donc, est-ce

qui est-ce qu'il se pourrait qu'il y ait toujours de

nouvelles méthodes? Ça, ça reste à voir, ya quand même des

bonnes, des bonnes réponses du côté de Facebook par exemple,

seulement à vendre des publicités électorales a des

gens qui ont le droit de le

faire, donc. Avant 2016, on n'avait même pas besoin de

prouver qu'on avait le droit d'acheter une publicité

électorale. Mais pas besoin de prouver qu'on habitait dans le

pays en question. Donc il y a des publicités dans l'élection

de Miss qui ont été achetés avec des roubles quand même. Faut le

faire donc ça c'est c'est plus permis. Salon, salon des

nouvelles, des nouvelles règles, donc on partait de loin. T'as

mentionné tantôt les groupes Facebook, je pense que c'est

important d'y revenir hein, parce que de plus en plus ils

prennent la place et c'est peut-être plus difficile pour

Facebook de devoir de surveiller ce qui se passe dans ces gros

plan. Tout à fait. Donc la nouvelle mode c'est les groupes

plutôt que les pages. Moi, depuis que Facebook a changé son

algorithme, il y a à peu près 2 ans, donc on a dit que bon, on

voulait arrêter la propagation des pages qui ont des des, des

histoires énormes et qui mettent de l'avant toutes sortes

d'informations trompeuses. Donc on a dit, on va prioriser les

groupes et les amis, donc vous allez voir plus de publications

sur votre fil d'actualité qui proviennent de veau groupé de

vos amis en se disant, mais plutôt que de suivre des pages

qui recrache n'importe quoi, les gens vont suivre que leurs amis

disaient, donc on va, on va créer un un plus gros sentiment

de communauté à l'intérieur de

Facebook et. C est que le but de Facebook c'est justement de

connecter les gens ensemble. Il y a eu un effet dont on

s'attendait pas, c'est que les groupes Facebook sont devenu le

haut lieu de la mobilisation politique sur la plateforme.

Donc il y a des bons côtés, il y a des mauvais côtés aussi.

Clairement une des choses avec les groupes, c'est que tout le

monde peut participer à la discussion, donc une page te.

23 personnes qui gèrent une page qui parle à leur auditoire de

100000 personnes et qui.

Envoie des messages et que ces gens-là consomme passivement,

ils peuvent commenter mais consomme facilement. Dans un

groupe qui a 100000 abonnés, les 100000 personnes du groupe ont

accès aux autres. 100000 personnes du groupe. Donc il y a

énormément de publication chaque jour dans les communautés qui

sont très mobilisés, donc ça fait que ça crée quasiment comme

un fil d'actualité parallèle ou tu peux passer des heures dans

le groupe a juste voir défiler des opinions des gens dans ce

groupe là et ça peut créer bon un effet quasiment de bulle,

donc conseillé chambre découle exactement, on s'inquiétait de

la chambre d'écho. Mais les groupes Facebook, ça peut

devenir en quelque sorte une chambre d'écho, donc un peu

plus. Ouais, exactement.

Continue.

Entre 2016 et 2019, voire 2020, le principal véhicule des infos

en 2016, Facebook mais aujourd hui, il y a d'autres plateformes

qui sont utilisées, des plateformes qui se transforme

rapidement on je pense ici aux plateformes chiffres et là il y

a des plateformes qui s'appelle comme télégramme, WhatsApp des

des des qui sont en qui sont fondamentalement des services de

messageries chiffrées. Donc personne peut voir les

discussions, à part les 2 personnes qui se parlent oui et

ça c'est c'est créer pour ça, donc c'est un peu en réponse à

toutes les les controverses.

Qui atteignent la vie privée sur les réseaux sociaux. Donc on a

créé cette plateforme là pour que les gens puissent avoir des

discussions en en étant tout à fait à l'aise. Hum, parce que

personne peut aller voir qu'est-ce qui se dit? Des

applications comme WhatsApp? C'est très très très très

populaire dans certains pays et dans dans certaines régions du

monde, ça devient. C'est ça l'internet, parce que ça utilise

très peu de données et. Et donc les gens peuvent s'envoyer des

messages avec ça et on crée des des salles de clavardage ou des

listes où les gens peuvent s'envoyer des messages et.

La désinformation circule très rapidement dans ces dans ces

cercles là. Le problème, c'est que c'était pas membre de ces

salles de clavardage. La personne peut aller voir donc

difficile pour les autorités ou les journalistes d'aller voir

qu'est-ce qui circule sur ça. On a vu des effets très néfastes

avec avec tout ça en Inde et en Afrique en particulier dans

certains pays, ya eu des gens qui sont morts à cause de

fausses nouvelles qui ont circulé dans ces plateformes là,

donc c'est une une tout autre situation. Si on veut Facebook

c'est. Facebook et Twitter, c'est quand même assez public ou

quoi? Que les groupes Facebook, ça peut être très très privé là,

mais des plateformes comme WhatsApp ou telegram qui

d'ailleurs dans l'état islamique utilise télégramme pour

s'organiser. Donc tout dire donc ouais, donc ça ça compliqué la

donne. Ouais ça compliqué la donne pour les autorités. Dans

quelle mesure où ils le font en ce moment de de regarder ça avec

leur loupe et de faire en sorte qu'il n'y a pas de dérapage.

Ouais puis sacré tour de situation où les autorités

demandent à ces plateformes là de créer ce qu'on appelle un

backdoor. Donc, une porte par l'arrière pour permettre aux

autorités de de pouvoir briser le chiffrage et d'aller voir ce

qui se dit donc on justifie, bon, il y a des terroristes là

dessus. Nous on veut avoir le droit de pouvoir briser le

chiffrage pour pour pouvoir aller épier ces gens-là. Sacré

toutes sortes de questions éthiques. Là parce que si, si la

porte d'en arrière existe et qu'on la crise supposément juste

pour les autorités, qu'est-ce qui empêche quelqu'un d'autre,

de de, de l'utiliser puis d'aller voir ce qui se passait

de des pieds, des conversations privées, donc ça soulève toutes

sortes de de questions.

Mais qui sont des des questions sociales fondamentales, à quel

niveau les autorités devraient avoir le pouvoir de de

surveiller ce qui se passe? Donc c'est pas des des questions qui

sont vraiment noire ou blanche, ou très simple à à tranché. En

terminant, je pense qu'on peut affirmer que ça va être un peu

un test ultime. La 2020 pour Facebook, donc on peut pas voir

l'avenir, donc on peut pas prédire ce qui va se passer. Une

chose est certaine, c'est que absolument tous les yeux sont

rivés sur les plateformes de réseaux sociaux à voir ce qui va

se passer. On sait déjà que les les gouvernements et la

population et les médias demande assez plate forme là de

surveiller sa et de, de s'assurer que 2016 ne se

reproduisent pas. Donc c'est c'est clair que je pense que on

verra pas le même résultat qu'en 2016 où il y aura une campagne

massive d'ingérence qui va avoir lieu et qu'on le sache juste

après. Mais encore là, peut-être que peut-être que je me trompe

complètement, puis on, ça reste à voir. On peut juste ne pas le

souhaiter. Par exemple pour la démocratie américaine. Merci

beaucoup James. La prochaine.

C'est tout pour le balado de aujourd'hui on a besoin de

vous, de vos lumières et de vos idées pour nous écrire.

Ça s'explique à commercial radio, trait d'union Canada,

point C à je m'appelle Alexis de lancer. À bientôt.
