Quand le pillage commence les fusillades

commence. Ce message envoyé par Donald Trump à ses 80 millions

d'abonnés sur Twitter a été retiré par l'entreprise, pour

qui il s'agit d'une apologie de la violence. Un autre tweet du

président américain liant vote par correspondance et fraude

massive, a été signalé par Twitter comme étant trompeur. En

plus de provoquer la colère du président Trump, ces 2 décisions

récentes de l'entreprise contre un de ses plus populaires

utilisateurs à aussi provoqué tout un débat sur les droits,

responsabilités et obligations des grands réseaux sociaux.

Notre question, ou commence? Où s'arrête la responsabilité des

réseaux sociaux face au contenu produit par leurs utilisateurs?

Notre invité, Pierre trudel, professeur à la faculté de droit

de l'université de Montréal. Moi, je m'appelle Alexis de

lancer et c'est parti pour ça s'explique le balado, qui

s'intéresse à l'actualité. Une question à la fois.

Drôle.

Car.

Play Store.

Plateforme.

Trump est parti en croisade contre les grands réseaux

sociaux. Ben concrètement, il a signé un décret présidentiel

pour, dit-il, protéger la liberté d'expression et les

droits du peuple américain. Tout ça parce que selon lui, et je

site, la responsabilité des géants des médias sociaux comme

Twitter, et protéger sur la base de la théorie salon, laquelle

ils sont une plateforme neutre, ce qu'ils ne sont pas fins de

citation. Avant d'expliquer en quoi consiste ce décret,

commençons par la base Pierre trudel. Qu'est-ce qui encadrent

légalement la publication des contenus sur les réseaux sociaux

en ce moment? Alors, ce qui est encore légalement, les réseaux

sociaux, c'est une loi qui a été adoptée dans le courant des

années 90, au moment où internet a commencé à devenir un espace

grand public. Une loi qui à la fois protège les réseaux sociaux

lorsqu'il décide d'enlever du contenu qui a été mis en ligne

par par quelqu'un d'autre part

1/3. Et en même temps la même loi les protège aussi, s'ils

décident de maintenir le contenu, de ne pas enlever du

contenu, même si ce contenu pourrait contrevenir aux lois et

donc la loi alur. Les exemples de responsabilité, la loi leur

donne ce qu'on appelle une immunité à l'égard de toute

responsabilité qui pourrait résulter soit d'un geste positif

par lequel elles auraient enlevé du contenu ou simplement le

simple fait qu'elles auraient laissé du contenu en ligne.

Dans l'un ou l'autre des cas, elle bénéficie d'une immunité

qui prévaut aux états unis. Mais il y a la France aussi qui

récemment, il est allé d'une initiative en ce sens, là oui.

Alors le cadre que nous avons eu est un cadre extrêmement

protecteur pour les réseaux sociaux. en France, la règle qui

prévaut, c'est que les réseaux sociaux sont pas responsables à

priori pour le contenu qui est mis en ligne par les tiers, mais

elles peuvent le devenir dès lors qu'ils ont connaissance du

caractère illicite du contenu.

Et en France, on a imité aussi une loi qui a été adoptée en

2018 en Allemagne.

Pour imposer un délai encore plus court aux réseaux sociaux

pour retirer du contenu haineux ou du contenu qui constituent

des appels au terrorisme. Donc ça va un peu plus loin en France

et par exemple ici au Canada. Ouais. Alors au Canada, au

Québec, à une loi spécifique qui me reprend l'approche

européenne, c'est-à-dire que au Québec, en vertu des lois du

Québec, un réseau social n'est pas responsable tant et aussi

longtemps qu'on ne lui a pas indiqué que le contenu qui a été

mis en ligne sur sa plateforme

par. Un usager par un internaute contrevient à la loi.

On observé, c'est qu'en plus des balises légales, les différentes

plateformes se sont mis à faire de plus en plus de modération

des contenus selca, de Twitter avec sa nouvelle approche.

Tellement critiquée par le président Trump, comme il

l'explique ici, Sylvain carle, associé chez Real Ventures et

ancien employé de Twitter Twitter a lancé sur sa

plateforme pour la coque vide des nouvelles étiquettes, donc

des nouvelles façons d'identifier des messages.

Pour permettre de contextualiser ces messages là et là, ils ont

décidé de l'appliquer au tweet politique et non pas le moindre

des Twitter politiques. Donald Trump, ça n'a pas été une

décision prise à la légère, j'en suis certain. Ils ont

probablement considérer qu'ils avaient les assise légale et

juridique suffisante pour aller dans cette direction là. Je

pense pas que je pense qu'il s'y attendait certainement, qu'il y

a eu des représailles où et les amorces dont on voit peut-être

ici les premières, les premiers signes alors, monsieur trudel,

sur quelle base légale les différents réseaux sociaux font

de la. Modération en ce moment en fait la principale base

légale sur laquelle il s'appuie pour faire de la modération,

c'est que ce sont des entreprises privées, se sont des

espaces privés. C'est un peu comme le salon chez vous. Si je

vais chez vous et que je parle sujet ou que je dis des mots qui

vous semblent inacceptables, Ben je peux vous inviter à sortir.

Alors c'est exactement cette même base légale qui s'applique

aux réseaux sociaux. Parce qu'il faut jamais perdre de vue que ce

sont des entreprises privées.

Alors quand monsieur Trump, officiellement, ne fait rien

d'illicite au sens de la loi sur Twitter, qu'est-ce qui permet à

Twitter d'identifier les tweets et de dire aux gens, mais

attention, ceci est trompeur, alors c'est la loi qui leur

donne cette immunité. Aux états unis leur permet aussi de

commenter les propos des des gens qui vont sur le réseau

social et au plan juridique que le fait d'associer un message,

un étiquette en disant nous pensons que ce message est

trompeur. Nous pensons que ce message est un appel à la

violence, mais c'est ça s'analyse, un peu comme si

Twitter mettait un étiquette sur certains propos de manière à

éclairer ses usagers, un peu comme le font les radio

diffuseurs dans d'autres contextes, lorsqu'ils disent,

nous vous prévenons que cette émission ne comporte un langage

qui pourrait déplaire, où qui pourraient offenser certains

spectateurs, alors c'est de la même nature. L'entreprise

Twitter ou un autre réseau social bain peut en quelque

sorte à coller.

Une étiquette ou une mention à un propos de manière à éclairer

ses usagers sur la valeur. On devrait accorder où là?

Précaution qu'il faut avoir à l'égard de certains messages.

Facebook Or original plateformes général should be arbres of

triste. Sa cavale dans Jocelyne get down terms of Arms sign

boîte. Je ne sont pas tous les réseaux sociaux qui ont la même

approche. On a pu le constater rapidement. On attendait ces

propos de monsieur Zuckerberg, le PDG de Facebook, qui a pris

ses distances face à Twitter, Facebook ou les plateformes

internet en général, ne devrait pas être des arbitres de la

vérité, disait il au réseau

aussi NBC. Cette position belle si butée à la grogne des

employés de Facebook qui auraient préféré que

l'entreprise signal certains message de Donald Trump. Depuis,

monsieur Zuckerberg a promis de revoir les politiques de sa

plateforme web. Mais monsieur trudel, pourquoi Facebook refuse

pour l'instant de faire comme Twitter en fait, quels sont les

risques associés à une telle

approche? Ouais, mais les risques d'une approche comme

celle-là, c'est de savoir, on peut savoir où ça commence,

mais vous, c'est fini ça, ça devient beaucoup plus

difficile lorsqu'il s'agit de d'identifier des messages

comme étant possiblement fautif. Où possiblement faux.

Il sait pas, il y a des qu évidents. Il y a des zones

grises, alors une entreprise qui se lance dans cette dans cette

activité, d'essayer de départager ce qui serait

messages conformes à la vérité et ce qui ne le serait pas. Mais

elle s'expose évidemment à des risques de savoir. Mais pourquoi

est-ce que vous avez identifié ce message? Là était faux mais

pas le, mais pas l'autre qui n'est pas, qui n'est pas

davantage fiable que le premier et donc il y a une espèce de

piège qui a beaucoup d'entreprises, hésitent avec

raison à affranchir.

Est-ce que, à partir du moment où on commence à se porter

garant de ce qui est dit dans

ces plateformes. L'entreprise cesse d'être une plateforme,

mais ça devient comme un éditeur finalement, donc c'est cette

ligne mince entre. À quel moment une plateforme qui se veut un

lieu ouvert à tous sujets bien sûr, au respect d'un certain

nombre de règles de bon comportement. À partir de quel

moment? Si la plateforme va trop loin dans l'étiquetage des

contenus. Mais elle peut se faire reprocher d'en avoir trop

fait ou de ne pas en avoir fait assez selon les contenus.

J'ai pu exposer en quelque sorte à ce qu'on critique son

cc mécanismes par lesquels elle décide d'étiqueter ou non

le contenu comme étant violent où possiblement fautif.

Mais parlons du décret maintenant présidentiel, du

président américain. Qu'est-ce qu'il vient changer dans le

contexte actuel, dans l'encadrement des contenus

publiés sur les réseaux sociaux?

Alors, ce que le décret de monsieur Trump vient faire,

c'est d'inviter des organismes de réglementation de la fédéral

Trade commission. À revoir les pratiques des réseaux sociaux.

Et essentiellement à ce que le décret divin c est ce que le

fait de de étiquetée comme ça. Les contenus ça équivaut pour

ces réseaux sociaux là à exercer ce qu'on appelle une fonction

éditoriale, c'est à dire la fonction par laquelle un média

examining contenu juge le cerf valeur de sa fiabilité et prend

la responsabilité de le diffuser. C'est ce que font les

médias traditionnels. On va dire qu'ils exercent alors leur

responsabilité éditoriale. Et évidemment, avec la

responsabilité éditoriale, vient l'obligation de répondre si

jamais le contenu est contraire aux lois. Lorsque le décret de

Trump vient remettre en question, c'est justement cette

immunité dont on parlait un peu plus tôt. L'immunité qui

provient de cette loi là adoptée dans les années 90 et qui se

fondé sur l'idée que les réseaux sociaux étaient des espaces qui

accueillait des propos qui venait de n'importe quel

internaute, étant aussi longtemps que ça vient, ça vient

pas d'eux-mêmes, les réseaux

sociaux. Ils sont pas responsables de ces propos là.

Alors que Trump vient dire dans son décret ebay, à partir du

moment où le réseau social se met à interposer un processus

par lequel il va étiqueter, dans lequel il va être désigné tel

contenu, il va dire tel contenu, il peut être faudrait le contenu

peut être violent. Alors là, la prétention de de monsieur Trump

c'est de dire bah il joue un rôle éditorial et s'y joue un

rôle éditorial, mais il devrait alors être responsable du

contenu qui est diffusée dans la

plateforme. Et l'homme dira ces entreprises là, vous êtes

désormais responsable de tout ce qui se diffusent sur la

plateforme, c'est remettre radicalement en question leur

modèle d'affaires, parce que c'est ce sont pas du tout des

entreprises qui ont structuré pour analyser et évaluer le

bien-fondé de tout ce qui va en ligne. C'est cette entreprise

qui qui réussissent à faire des à, créer de la valeur, à faire

de l'argent en assurant la diffusion instantanée de tout.

Tout propos qu'un utilisateur souhaite mettre en ligne et ce

ne sont pas des gens qui cherchent à qui, qui, qui sont

des éditeurs. Alors le décret Trump viendra en quelque sorte.

Les responsables comme un éditeur, dès lors qu'elles

utilisent leurs facultés.

De. De mettre des étiquettes sur les contenus, mais sur le fond

des choses, Donald Trump n'est pas le seul à évoquer ces

questions. D'autres le font. C'est le cas dans un certain

sens, de Patrick White, le responsable du programme de

journalisme à l'uqam. Donc, il y a un manque de transparence du

côté de Twitter, on connaît pas sa méthodologie sur la

vérification des faits. Alors en fait, ils ont même pas de

vérificateurs de faits, contrairement à Facebook. Donc

je sais pas comment ils vont appliquer clairement tout ça.

Quels sont les critères et si tu

le fais pour. Monsieur Trump, qu'est-ce que tu fais avec

Maxime Bernier, par exemple? Avec le président brésilien,

monsieur bolson araud, le gouvernement chinois et plein

d'autres personnalités, qui publie à tous les jours des

documents trompeur, des informations controversées donc.

On le voit monsieur trudel? La pratique qui commence à se

répandre d'édicter certains contenus pour alerter les

lecteurs, mais elle se bute à un problème de méthode ou de

technique pour mettre son application et monsieur Trump

nous le rappelle, ça absolument, et ça, c'est une le le décret

monsieur Trump a au moins le mérite de rappeler ce problème

qui est un problème qui existait

bien avant. Monsieur Trump, un problème que tu vas été signalé

dans la littérature, c'est à dire quel est le rôle que

devrait jouer les réseaux sociaux? On s'entend tous pour

dire que ce ne sont pas des éditeurs, mais de quelle manière

devrait exercer leur rôle de déterminer à un moment donné que

tel message, si il n'est pas bloqué au moins, pourrait être

l'objet d'une certaine mise en garde? Bon à mentionné un peu

plus tôt en Europe.

En France et en Allemagne le l'approche qui a été retenue, ça

a été de signe de dire à l'égard de certains contenus comme le

contenu constitué, un appel à la violence ou du contenu à saveur

terroristes vers les réseaux sociaux devaient avoir

l'obligation d'agir rapidement pour retirer ce contenu et donc

il y a un un questionnement un peu partout dans le monde pour

modifier ou à tout le moins rendre plus sophistiqué. Là, ce

qu'on pourrait appeler le régime de responsabilité des réseaux

sociaux. On veut d'une part, on veut éviter de les transformer

en organisme qui font de la censure privée, mais d'un autre

côté, on reconnaît qu'ils ont un certain rôle à jouer pour éviter

que des messages qui sont notoirement dommageable

circulent sans que personne n'intervienne. Pour éviter que

que ces messages ne se répande à la vitesse de la lumière.

Facebook il faut savoir ils ont nommé des tiers ce parti, alors

des agences de presse, et cetera, qui font la vérification

des nouvelles. Mais Pour ce faire, il faut que vous, comme

usagés, hein, vous signaliez cette nouvelle là où cette

publication là et ensuite Facebook, voilà réviser. Ils ont

même aussi des modérateurs qui s'occupe un devoir à ce que les

contenus violents ou à caractère ****** soit retiré, comme l'a

décrit Nadia, série Yoko, chargé de cours à l'école des médias de

l'uqam. La méthode Facebook, c'est entre autres la mise sur

pied de partenariats avec des tiers. Ce parti des médias de

vérification ou des fact checkers. Radio-Canada est

d'ailleurs un de ses partenaires par le biais de l'équipe, des

décrypteurs dont je fais moi-même partie. Alors, ce type

d'approche, monsieur trudel, est-ce que ça peut inspirer en

quelque part le un cadre juridique éventuel pour mieux

encadrer les contenus qu'on retrouve sur ces plateformes?

Oui, c'est une des pistes qui est souvent envisagée,

c'est-à-dire d'intégrer dans le processus des un certain nombre

d'expertise. Pour aider l'usager de la plateforme à faire le

départage entre ce qui est fiable et ce qui ne l'est pas,

où ce qui est complètement vrai vs ce qui est controversé,

évidemment, elle soulève un certain nombre dans

d'inconvénient dans la mesure où plus on se rapproche d'un modèle

par lequel on va mettre de côté des contenus, plus on peut avoir

des réserves sur le fait qu'une entreprise qui Rappelons le

demeure, une entreprise privée.

Il se met à devenir juge de ce qui est conforme à

la vérité ou ce qui est conforme à la réalité.

Et ce qui est conforme à la loi. Aussi parce que un des grands

enjeux, bien sûr, c'est que on dans la plupart des pays

démocratiques, on va admettre que on puisse retirer des

contenus temps et aussi longtemps qu'ils ne sont pas

conformes à la loi. Mais encore faut-il qu'on déterminent que

les contenus ne sont pas conformes à la loi. Or, le

modèle que Facebook met de l'avant avec son projet qu'on a

appelé sa cour suprême, bah c'était de devenir en quelque

sorte un juge privé.

Qui déterminerait si oui ou non le contenu est conforme à la loi

et là, ça posé un problème parce que est-ce que ces plateformes

qui, toutes privées qu'elles soient, sont devenus les places

publiques de notre époque? Dans quelle mesure on peut laisser

assez seule plateforme le soin de déterminer ce qui est ou non

conforme à la loi, conforme ou non à la vérité? Alors il y a

les gens qui disent c'est acceptable aussi longtemps qu'on

utilise des partenaires qui viennent en quelque sorte.

2nd de la plateforme de réseau social pour aider à départager

le vrai du faux, d'autres vont plus loin, ils disent, il

faudrait probablement intégré dans le système un mécanisme de

type cyber tribunal, c'est-à-dire par laquelle un

juge viendrait en ligne juge étatique, donc un juge

indépendant viendrait en ligne trancher sur ce qui est

contraire ou non à la loi. Et là, on aura un modèle par lequel

Ben au moins on s'assurait d'obtenir que les contenus qui

sont contraires aux lois.

Sont évacués rapidement du du réseau social, sans pour autant

avoir un modèle qui fait en sorte que le réseau social

pourrait être tenté d'éliminer des contenus au cas où ce serait

contraire à la loi ou pour minimiser ce risque d'avoir un

jour. Répondre ce qui pourrait avoir comme effet de censurer

des contenus qui, bien que détestables, sont pas contraires

aux lois. Mais que ce soit la méthode tweeté la méthode

Facebook avec les tierces parties ou encore celle d'un

juge qui viendrait arbitrer ce qui se dit, ce qui s'écrit sur

ces plateformes se pose toujours le même problème, le flot

ininterrompu de publication. Un volume excessivement grand de

publication. Comment justement répondre à cette demande face à

un tel flux d'informations? Parce qu'il avait tout à fait

raison. Le vrai défi, c'est celui là, si on parle de flot

considérable d'informations. Pour l'heure, les entreprises

ont commencé à examiner des solutions fondées sur

l'intelligence artificielle, sur le les procédés de

l'intelligence artificielle pour tenter de détecter les contenus

qui sont problématiques et les écarter avant même qu'il puisse

aller en ligne.

Et il faut quand même garder à l'esprit que déterminée, où

départager entre le propos vrai, le propos qui ne l'est

pas, le propos mensongers, le propos qui incitent à la

violence, le propos qui est simplement un regard critique

sur certaines prises de position, c'est un un travail

extrêmement difficile. Il faut se poser la question, est-ce

que un jour on aura des technologies d'intelligence

artificielle qui nous permettrait de reconnaître de

manière automatisée?

Les contenus qui sont préjudiciables et contraire aux

lois versus les contenus qui sont légitimes, c'est un défi.

Je dirais que c'est le défi de notre temps, finalement, de

déterminer comment on va faire pour le je dirais réguler ce

flot d'informations, faut quand même jamais perdre de vue que

c'est la première fois dans l'histoire humaine qu'on a un

système de communication qui permet à chacun qui est doté

d'un appareil connecté à chacun

de diffuser. Pratiquement n'importe quoi et donc c'est la

première fois que l'espèce humaine, si vous voulez être

appelé à relever ce défi de départager entre le acceptable

et ce qui doit absolument être supprimé, ce n'est pas une mince

affaire et est déjà, en partant, encadrer et réguler ce qui

circule sur le web. Ça n'a jamais été simple, mais là,

effectivement, on est face à tout un défi. Monsieur trudel,

Pierre trudel, merci infiniment pour cet échange et cette

échange d'informations très

éclairantes. Une prochaine semaine prochaine?

C'est là dessus que s'achève un autre épisode du balado ça

s'explique avec toute l'équipe. Je vous remercie de

nous suivre jour après jour. Si vous souhaiter qu'on

abordent un sujet en particulier, n'hésitez pas,

écrivez nous à ça s'explique. A commercial radio trait

d'union Canada, point C à moi, je m'appelle Alexis de lancer

à demain.
